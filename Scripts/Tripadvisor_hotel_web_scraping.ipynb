{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tripadvisor Hotel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Firefox browser installed!\n",
    "#%pip install helium\n",
    "#%pip install bs4\n",
    "#%pip install pandas\n",
    "#%pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helium import *\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_NAME = ['HOTEL_NAME', 'HOTEL_RATING', 'HOTEL_PRICE', 'HOTEL_LOCATION', 'HOTEL_REVIEW_URL', 'REVIEW_RATING', 'REVIEW_DATE', 'REVIEW_HELPFUL_VOTES', 'REVIEW_TEXT']\n",
    "ROOT_URL = 'https://www.tripadvisor.com/'\n",
    "MAX_HOTEL_PAGES = 1\n",
    "MAX_REVIEW_PAGES = 2\n",
    "URL_COLUMN_NAME = 'HOTEL_URL'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Hotels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try:\n",
    "#    writer = csv.DictWriter(open('tripadvisor_best_hotels_data.csv', 'w', encoding='UTF8', newline=''), fieldnames=COLUMNS_NAME, delimiter=',', lineterminator='\\r')\n",
    "#    writer.writeheader()\n",
    "#except IOError:\n",
    "#    print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Worst Hotels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try:\n",
    "#    writer = csv.DictWriter(open('tripadvisor_worst_hotels_data.csv', 'w', encoding='UTF8', newline=''), fieldnames=COLUMNS_NAME, delimiter=',', lineterminator='\\r')\n",
    "#    writer.writeheader()\n",
    "#except IOError:\n",
    "#    print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hotels by list (CSV file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    writer = csv.DictWriter(open('tripadvisor_hotels_by_list.csv', 'w', encoding='UTF8', newline=''), fieldnames=COLUMNS_NAME, delimiter=',', lineterminator='\\r')\n",
    "    writer.writeheader()\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_browser(URL=None):\n",
    "    # Setting browser settings\n",
    "    Config.implicit_wait_secs = 30\n",
    "    options = webdriver.FirefoxOptions()\n",
    "    options.preferences[\"permissions.default.geo\"] = 1\n",
    "    if(URL != None):\n",
    "        return start_firefox(url=URL, options=options, headless=True)\n",
    "    else:\n",
    "        return start_firefox(options=options, headless=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews_info(reviews, row, page):\n",
    "    scroll_down(4500)\n",
    "    wait_until(S(\"//span[text()='Read more']\").exists, 60)\n",
    "    \n",
    "    try:\n",
    "        # Expand the review\n",
    "        click('Read more')\n",
    "        # Get review's info\n",
    "        for x in range(len(reviews)):\n",
    "            review = reviews[x]\n",
    "            # REVIEW_RATING\n",
    "            row[COLUMNS_NAME[5]] = review.find('div', class_='Hlmiy F1').find_all('span')[0].get('class')[1]\n",
    "            # REVIEW_DATE\n",
    "            row[COLUMNS_NAME[6]] = review.find('span', class_='teHYY _R Me S4 H3').text\n",
    "            # REVIEW_HELPFUL_VOTES\n",
    "            if(review.find('span', class_='hVSKz S2 H2 Ch sJlxi') != None):\n",
    "                row[COLUMNS_NAME[7]] = review.find('span', class_='hVSKz S2 H2 Ch sJlxi').text\n",
    "            # REVIEW_TEXT\n",
    "            row[COLUMNS_NAME[8]] = review.find('div', class_='fIrGe _T').text\n",
    "            try:\n",
    "                print('Hotel: ' + row[COLUMNS_NAME[0]] + ' - ' + 'Review: ' + str(x+1) + ' - Page: ' + str(page+1))\n",
    "                writer.writerow(row)\n",
    "            except IOError:\n",
    "                print(\"I/O error\")\n",
    "    except:\n",
    "        print('ERROR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hotels_info(hotels, max_review_pages):\n",
    "    for x in range(len(hotels)):\n",
    "        hotel = hotels[x]\n",
    "        row = {}\n",
    "\n",
    "        # HOTEL_NAME\n",
    "        row[COLUMNS_NAME[0]] = hotel.find('a', class_='property_title prominent').text\n",
    "        # HOTEL_RATING\n",
    "        row[COLUMNS_NAME[1]] = hotel.find('div', class_='prw_rup prw_common_rating_and_review_count_with_popup linespace is-shown-at-mobile').find_all('a')[0].get('alt')\n",
    "        # HOTEL_PRICE\n",
    "        row[COLUMNS_NAME[2]] = hotel.find('div', class_='price __resizeWatch').text\n",
    "        # HOTEL_REVIEW_LINK\n",
    "        row[COLUMNS_NAME[4]] = ROOT_URL + hotel.find('a', class_='review_count').get('href')\n",
    "        \n",
    "        # Goes to the hotel's reviews\n",
    "        browser = start_firefox(url=row[COLUMNS_NAME[4]], headless=True)\n",
    "        wait_until(S(\"//div[@class='jvqAy']\").exists, 30)\n",
    "        sleep(10)\n",
    "        reviews_soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "\n",
    "        # HOTEL_LOCATION\n",
    "        row[COLUMNS_NAME[3]] = reviews_soup.find('span', class_='fHvkI PTrfg').text\n",
    "        \n",
    "        for y in range(max_review_pages):\n",
    "            reviews_soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "            get_reviews_info(reviews_soup.find_all('div', class_='YibKl MC R2 Gi z Z BB pBbQr'), row, y)\n",
    "            # Goes to the next reviews page\n",
    "            try:\n",
    "                go_to(ROOT_URL + reviews_soup.find('a', class_='ui_button nav next primary').get('href'))\n",
    "                reviews_soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "            except:\n",
    "                print('Max review page')\n",
    "                break\n",
    "            \n",
    "        kill_browser()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hotels_data_by_location(URL, max_hotel_pages):\n",
    "    # Start the browser\n",
    "    browser = start_browser(URL)\n",
    "    # Press \"See all\" button to show the navigation menu\n",
    "    wait_until(S(\"//span[text()='Check In']\").exists, 60)\n",
    "    wait_until(lambda: len(browser.page_source) > 0, 60)\n",
    "    sleep(3)\n",
    "    press(END)\n",
    "    scroll_up(600)\n",
    "    wait_until(Button('See all').exists, 60)\n",
    "    sleep(2)\n",
    "    click('See all')\n",
    "    sleep(15)\n",
    "\n",
    "    for x in range(max_hotel_pages):\n",
    "        soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "        get_hotels_info(soup.find_all('div', class_='ui_column is-8 main_col allowEllipsis'), MAX_REVIEW_PAGES)\n",
    "        set_driver(browser)\n",
    "        press(END)\n",
    "        click('Next')\n",
    "        wait_until(S(\"//span[text()='Check In']\").exists, 60)\n",
    "        sleep(3)\n",
    "        \n",
    "    kill_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hotels_data_by_search(URL):\n",
    "    # Start the browser\n",
    "    browser = start_browser(URL)\n",
    "    wait_until(S(\"//span[@class='title-match']\").exists, 60)\n",
    "    # Get html source code of the website\n",
    "    soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "    hotels = soup.find_all('div', class_='ui_columns is-mobile result-content-columns')\n",
    "    \n",
    "    for x in range(len(hotels)):\n",
    "        hotel = hotels[x]\n",
    "        row = {}\n",
    "\n",
    "        # HOTEL_RATING\n",
    "        row[COLUMNS_NAME[1]] = hotel.find('div', class_='prw_rup prw_common_responsive_rating_and_review_count').find('span').get('alt')\n",
    "        # HOTEL_REVIEW_LINK\n",
    "        row[COLUMNS_NAME[4]] = ROOT_URL + hotel.find('a', class_='review_count').get('href')\n",
    "\n",
    "        # Goes to the hotel's reviews\n",
    "        go_to(url=row[COLUMNS_NAME[4]])\n",
    "        wait_until(lambda: S(\"//div[@class='WXMFC b autoResize']\").exists or S(\"//div[@class='WXMFC b']\").exists or S(\"//div[@class='JPNOn b Wi']\").exists, 30)\n",
    "        wait_until(lambda: len(browser.page_source) > 0, 60)\n",
    "        print(len(browser.page_source))\n",
    "        reviews_soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "        \n",
    "        # HOTEL_NAME\n",
    "        row[COLUMNS_NAME[0]] = reviews_soup.find('h1', class_='QdLfr b d Pn').text\n",
    "        # HOTEL_LOCATION\n",
    "        row[COLUMNS_NAME[3]] = reviews_soup.find('span', class_='fHvkI PTrfg').text\n",
    "        # HOTEL_PRICE\n",
    "        if(reviews_soup.find('div', class_='WXMFC b') != None):\n",
    "            row[COLUMNS_NAME[2]] = reviews_soup.find('div', class_='WXMFC b').text\n",
    "        elif(reviews_soup.find('div', class_='JPNOn b Wi') != None):\n",
    "            row[COLUMNS_NAME[2]] = reviews_soup.find('div', class_='JPNOn b Wi').text\n",
    "        elif(reviews_soup.find('div', class_='WXMFC b autoResize') != None):\n",
    "            row[COLUMNS_NAME[2]] = reviews_soup.find('div', class_='WXMFC b autoResize').text\n",
    "\n",
    "        for y in range(MAX_REVIEW_PAGES):\n",
    "            reviews_soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "            get_reviews_info(reviews_soup.find_all('div', class_='YibKl MC R2 Gi z Z BB pBbQr'), row, y)\n",
    "            # Goes to the next reviews page\n",
    "            try:\n",
    "                go_to(ROOT_URL + reviews_soup.find('a', class_='ui_button nav next primary').get('href'))\n",
    "            except:\n",
    "                print('Max review page')\n",
    "                break\n",
    "    kill_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hotels_by_list(csv_path, column_name, max_review_pages):\n",
    "    hotels_df = pd.read_csv(csv_path)\n",
    "    hotels = hotels_df[column_name].to_list()\n",
    "    browser = start_browser()\n",
    "\n",
    "    for x in range(len(hotels)):\n",
    "        row = {}\n",
    "        go_to(hotels[x])\n",
    "        wait_until(lambda: S(\"//div[@class='WXMFC b autoResize']\").exists or S(\"//div[@class='WXMFC b']\").exists or S(\"//div[@class='JPNOn b Wi']\").exists, 30)\n",
    "        wait_until(lambda: len(browser.page_source) > 0, 60)\n",
    "        reviews_soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "\n",
    "        # HOTEL_NAME\n",
    "        row[COLUMNS_NAME[0]] = reviews_soup.find('h1', class_='QdLfr b d Pn').text\n",
    "        # HOTEL_RATING\n",
    "        row[COLUMNS_NAME[1]] = reviews_soup.find('a', class_='BNPpl q wfOFe _T Gi').find('span').get('class')[1]\n",
    "        # HOTEL_PRICE\n",
    "        if(reviews_soup.find('div', class_='WXMFC b') != None):\n",
    "            row[COLUMNS_NAME[2]] = reviews_soup.find('div', class_='WXMFC b').text\n",
    "        elif(reviews_soup.find('div', class_='JPNOn b Wi') != None):\n",
    "            row[COLUMNS_NAME[2]] = reviews_soup.find('div', class_='JPNOn b Wi').text\n",
    "        elif(reviews_soup.find('div', class_='WXMFC b autoResize') != None):\n",
    "            row[COLUMNS_NAME[2]] = reviews_soup.find('div', class_='WXMFC b autoResize').text\n",
    "        # HOTEL_LOCATION\n",
    "        row[COLUMNS_NAME[3]] = reviews_soup.find('span', class_='fHvkI PTrfg').text\n",
    "        # HOTEL_REVIEW_LINK\n",
    "        row[COLUMNS_NAME[4]] = hotels[x]\n",
    "\n",
    "        for y in range(max_review_pages):\n",
    "            reviews_soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "            get_reviews_info(reviews_soup.find_all('div', class_='YibKl MC R2 Gi z Z BB pBbQr'), row, y)\n",
    "            # Goes to the next reviews page\n",
    "            try:\n",
    "                go_to(ROOT_URL + reviews_soup.find('a', class_='ui_button nav next primary').get('href'))\n",
    "                wait_until(lambda: len(browser.page_source) > 0, 60)\n",
    "            except:\n",
    "                print('Max review page')\n",
    "                break\n",
    "    kill_browser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_hotels_data_by_location('https://www.tripadvisor.com/Hotels-g4-Europe-Hotels.html', MAX_HOTEL_PAGES)\n",
    "#get_hotels_data_by_search('https://www.tripadvisor.com/Search?q=worst%20hotel&searchSessionId=CFC88E23E91B7FA8D0D751E5DEE9F5D31663450804735ssid&sid=9D518B65B4454EF1A82B6656FCF7E39F1663452594116&blockRedirect=true&ssrc=h&isSingleSearch=true&geo=1&rf=3')\n",
    "get_hotels_by_list('tripadvisor_hotel_list_test.csv', URL_COLUMN_NAME, MAX_REVIEW_PAGES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d61fbcc3117b0ac5d1a9b011a6e6e6d6b00ccf7a03e181c5c6debb2edc6bab6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
