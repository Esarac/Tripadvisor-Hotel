{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REVIEW SUMMARIZER\n",
    "## TRIPADVISOR: HOTELS\n",
    "\n",
    "*   Esteban Ariza\n",
    "*   Johan Giraldo\n",
    "*   Mateo Valdes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers\n",
    "# %pip install torch\n",
    "\n",
    "# %conda config --add channels conda-forge\n",
    "# %conda config --set channel_priority strict\n",
    "# %conda install pytorch torchvision torchaudio pytorch-cuda=11.6 -c pytorch -c nvidia\n",
    "\n",
    "%pip install sentencepiece\n",
    "%pip install rouge-score\n",
    "%pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
    "import pandas as pd\n",
    "import csv\n",
    "from rouge_score import rouge_scorer, scoring\n",
    "import evaluate\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_CSV_PATH = \"../data/exploratory_analysis/tripadvisor_hotels_clean.csv\"\n",
    "HOTEL_DATA = pd.read_csv(INPUT_CSV_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_NAME = ['ORIGINAL_TEXT', 'SUMMARIZED_TEXT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    writer = csv.DictWriter(open('summarized_reviews.csv', 'w', encoding='UTF8', newline=''), fieldnames=COLUMNS_NAME, delimiter=',', lineterminator='\\r')\n",
    "    writer.writeheader()\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(review):\n",
    "    tokenized_text = tokenizer.encode('summarize: ' + review, return_tensors=\"pt\").to(device)\n",
    "    summary_ids = model.generate(tokenized_text,\n",
    "                                    num_beams=4,\n",
    "                                    no_repeat_ngram_size=2,\n",
    "                                    min_length=30,\n",
    "                                    max_length=100,\n",
    "                                    early_stopping=True)\n",
    "    row = {}\n",
    "    row[COLUMNS_NAME[0]] = review\n",
    "    row[COLUMNS_NAME[1]] = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    try:\n",
    "        writer.writerow(row)\n",
    "    except IOError:\n",
    "                print(\"I/O error\")\n",
    "    print('Summarized: ' + row[COLUMNS_NAME[0]] + ' to: ' + row[COLUMNS_NAME[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOTEL_DATA['REVIEW_TEXT'].apply(summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOTEL_SUMMARY = pd.read_csv('summarized_reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "predictions = HOTEL_SUMMARY[COLUMNS_NAME[1]].tolist()\n",
    "references = HOTEL_SUMMARY[COLUMNS_NAME[0]].tolist()\n",
    "results = rouge.compute(predictions=predictions, references=references)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitter(value):\n",
    "    return value.split()\n",
    "\n",
    "reference = list(map(splitter, HOTEL_SUMMARY[COLUMNS_NAME[0]].tolist()))\n",
    "candidates = list(map(splitter, HOTEL_SUMMARY[COLUMNS_NAME[1]].tolist()))\n",
    "\n",
    "# 1-gram:\n",
    "def bleu(reference, candidates, weights=(0.25, 0.25, 0.25, 0.25)):\n",
    "    result = 0;\n",
    "    for candidate in candidates:\n",
    "        result += sentence_bleu(reference, candidate, weights=weights)\n",
    "    result = result / len(candidates)\n",
    "    return result\n",
    "\n",
    "print('BLEU: %f' %bleu(reference, candidates))\n",
    "print('BLEU 1-gram: %f' %bleu(reference, candidates, (1, 0, 0, 0)))\n",
    "print('BLEU 2-gram: %f' %bleu(reference, candidates, (0, 1, 0, 0)))\n",
    "print('BLEU 3-gram: %f' %bleu(reference, candidates, (0, 0, 1, 0)))\n",
    "print('BLEU 4-gram: %f' %bleu(reference, candidates, (0, 0, 0, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Hotel and Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the csv file which contains all the reviews from all the hotels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_CSV_PATH = \"../data/exploratory_analysis/tripadvisor_hotels_clean.csv\"\n",
    "HOTEL_DATA = pd.read_csv(INPUT_CSV_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to import the T5 model (Is recommended to use 't5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL = 't5-base'\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = T5ForConditionalGeneration.from_pretrained(PRETRAINED_MODEL).to(device)\n",
    "tokenizer = T5Tokenizer.from_pretrained(PRETRAINED_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we create a file writer to save all the summarized reviews at run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_NAME = ['HOTEL_NAME','REVIEW_DATE','REVIEW_TEXT','REVIEW_SUMMARY']\n",
    "OUTPUT_CSV_PATH = \"../data/review_summarizer/summarized_reviews_by_year_and_hotel-base.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    writer = csv.DictWriter(open(OUTPUT_CSV_PATH, 'w', encoding='UTF8', newline=''), fieldnames=COLUMNS_NAME, delimiter=',', lineterminator='\\r')\n",
    "    writer.writeheader()\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"concatReviewsByYearAndHotel\" method will help us to group all the reviews by year and hotel name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "REVIEW_CONCATCHAR1 = \"{review concat}\"\n",
    "\n",
    "def fromDateToYear(value): #Clean CSV (yyyy-mm-dd)\n",
    "    return value.split(\"-\")[0]\n",
    "\n",
    "def concatReviewsByYearAndHotel(df):\n",
    "    df = df.copy()\n",
    "    df[\"REVIEW_DATE\"] = df[\"REVIEW_DATE\"].map(fromDateToYear)\n",
    "    df['REVIEW_TEXT'] = df[['HOTEL_NAME','REVIEW_TEXT','REVIEW_DATE']].groupby([\"HOTEL_NAME\",\"REVIEW_DATE\"])[\"REVIEW_TEXT\"].transform(lambda x: REVIEW_CONCATCHAR1.join(x))\n",
    "    return df[['HOTEL_NAME','REVIEW_DATE','REVIEW_TEXT']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"summarizeByYearHotel\" method is the one that uses the T5 model to summarize each review. After that, the method will save each summary in the output csv with the writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "REVIEW_CONCATCHAR2 = \".\"\n",
    "\n",
    "def summarizeEachAndConcat(reviews):\n",
    "    if len(reviews) <= 1:\n",
    "        return REVIEW_CONCATCHAR2.join(reviews)\n",
    "    else:\n",
    "        summary_prefix = 'summarize'\n",
    "        inputs = tokenizer([f'{summary_prefix}: ' + sequence for sequence in reviews], return_tensors=\"pt\", padding=True).to(device)\n",
    "        output_sequences = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"].to(device),\n",
    "            attention_mask=inputs[\"attention_mask\"]\n",
    "        )\n",
    "        output = tokenizer.batch_decode(output_sequences, skip_special_tokens=True)\n",
    "        return REVIEW_CONCATCHAR2.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizeByYearHotel(actRow):\n",
    "    summary_prefix = 'summarize'\n",
    "    tokenized_text = tokenizer.encode(f'{summary_prefix}: ' + actRow[\"REVIEW_TEXT\"], return_tensors=\"pt\").to(device)\n",
    "    summary_ids = model.generate(tokenized_text,\n",
    "                                    num_beams=4,\n",
    "                                    no_repeat_ngram_size=2,\n",
    "                                    min_length=30,\n",
    "                                    max_length=100,\n",
    "                                    early_stopping=True)\n",
    "    row = {}\n",
    "    row[COLUMNS_NAME[0]] = actRow[\"HOTEL_NAME\"]\n",
    "    row[COLUMNS_NAME[1]] = actRow[\"REVIEW_DATE\"]\n",
    "    row[COLUMNS_NAME[2]] = actRow[\"REVIEW_TEXT\"]\n",
    "    row[COLUMNS_NAME[3]] = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    try:\n",
    "        writer.writerow(row)\n",
    "    except IOError:\n",
    "                print(\"I/O error\")\n",
    "    print(row[COLUMNS_NAME[0]] + '-' + row[COLUMNS_NAME[1]] + ' -> len: '+ str( len(row[COLUMNS_NAME[2]]) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use the two above methods to summarize by year and hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by NAME and YEAR\n",
    "HOTEL_DATA_BY_YEARHOTEL = concatReviewsByYearAndHotel(HOTEL_DATA.dropna())\n",
    "print(\"Group by NAME and YEAR\")\n",
    "\n",
    "# Sort by text-len\n",
    "HOTEL_DATA_BY_YEARHOTEL[\"REVIEW_TEXT_LENGTH\"] = HOTEL_DATA_BY_YEARHOTEL[\"REVIEW_TEXT\"].map(len)\n",
    "HOTEL_DATA_BY_YEARHOTEL = HOTEL_DATA_BY_YEARHOTEL.sort_values(by = ['REVIEW_TEXT_LENGTH'], ascending = False)\n",
    "print(\"Sort by text-len\")\n",
    "print(HOTEL_DATA_BY_YEARHOTEL.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each row summarize by all summaries\n",
    "for index, row in HOTEL_DATA_BY_YEARHOTEL.iterrows():\n",
    "    row[\"REVIEW_TEXT\"] = summarizeEachAndConcat(row[\"REVIEW_TEXT\"].split(REVIEW_CONCATCHAR1))\n",
    "    summarizeByYearHotel(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the summarizing is done, we can import the generated csv into a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOTEL_SUMMARY = pd.read_csv(OUTPUT_CSV_PATH)\n",
    "HOTEL_SUMMARY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROGUE value of the summaries is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "predictions = HOTEL_SUMMARY['REVIEW_SUMMARY'].tolist()\n",
    "references = HOTEL_SUMMARY['REVIEW_TEXT'].tolist()\n",
    "results = rouge.compute(predictions=predictions, references=references)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the BLEU value of the summaries is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitter(value):\n",
    "    return value.split()\n",
    "\n",
    "reference = list(map(splitter, HOTEL_SUMMARY['REVIEW_TEXT'].tolist()))\n",
    "candidates = list(map(splitter, HOTEL_SUMMARY['REVIEW_SUMMARY'].tolist()))\n",
    "\n",
    "# 1-gram:\n",
    "def bleu(reference, candidates, weights=(0.25, 0.25, 0.25, 0.25)):\n",
    "    result = 0;\n",
    "    for candidate in candidates:\n",
    "        result += sentence_bleu(reference, candidate, weights=weights)\n",
    "    result = result / len(candidates)\n",
    "    return result\n",
    "\n",
    "print('BLEU: %f' %bleu(reference, candidates))\n",
    "print('BLEU 1-gram: %f' %bleu(reference, candidates, (1, 0, 0, 0)))\n",
    "print('BLEU 2-gram: %f' %bleu(reference, candidates, (0, 1, 0, 0)))\n",
    "print('BLEU 3-gram: %f' %bleu(reference, candidates, (0, 0, 1, 0)))\n",
    "print('BLEU 4-gram: %f' %bleu(reference, candidates, (0, 0, 0, 1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32fe028544ad451da7fd425bd970f9d43d891a9dcc481ea9112199e2f0c30cfa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
