{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA\n",
    "by Esteban Ariza Acosta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyldavis\n",
    "%pip install pyldavis.gensim\n",
    "%pip install spacy\n",
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import spacy\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download nltk dictionaries (stop words)\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/exploratory_analysis/tripadvisor_hotels_clean.csv\")\n",
    "reviews = df[\"REVIEW_TEXT\"].values.tolist()\n",
    "hotels = df['HOTEL_NAME'].values.tolist()\n",
    "\n",
    "#Eliminate puntiation marks\n",
    "reviews = [r.translate(str.maketrans('','',string.punctuation)) for r in reviews]\n",
    "\n",
    "#Lower case\n",
    "reviews = [r.lower() for r in reviews]\n",
    "\n",
    "#Split words\n",
    "reviews = [r.split(' ') for r in reviews]\n",
    "\n",
    "#Blank spaces\n",
    "reviews = [list(filter(lambda r: not (not r), review)) for review in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate common words\n",
    "sw = list(set(stopwords.words('english')))\n",
    "reviews = [list(filter(lambda r: r not in sw, review)) for review in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = Dictionary(reviews)\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in reviews]\n",
    "print(corpus[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[(id2word[i], freq) for i, freq in doc] for doc in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTERS = 6\n",
    "# Build LDA model\n",
    "lda_model = LdaModel(corpus=corpus,\n",
    "                   id2word=id2word,\n",
    "                   num_topics=CLUSTERS,\n",
    "                   random_state=0,\n",
    "                   chunksize=100,\n",
    "                   alpha='auto',\n",
    "                   per_word_topics=True)\n",
    "\n",
    "# pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data = []\n",
    "for i in range(len(doc_lda)):\n",
    "    act_class_data = [hotels[i]]\n",
    "    topics = doc_lda[i][0]\n",
    "    for topic in topics:\n",
    "        act_class_data.append(topic[1])\n",
    "    class_data.append(act_class_data)\n",
    "\n",
    "cdf_columns =[str(i+1) for i in range(CLUSTERS)]\n",
    "cdf_columns.insert(0, \"HOTEL\")\n",
    "cdf = pd.DataFrame(data=class_data, columns=cdf_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf[\"CLUSTER\"] = cdf[\"1\"] + cdf[\"2\"] + cdf[\"3\"] + cdf[\"4\"] + cdf[\"5\"] + cdf[\"6\"]\n",
    "doc_lda[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcdf = cdf.groupby('HOTEL').mean()\n",
    "gcdf.to_csv(f\"lda_prob_{CLUSTERS}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import hotel cluster\n",
    "def cluster_map(row):\n",
    "    values = [i for i in row[1:]]\n",
    "    max_value = max(values)\n",
    "    return values.index(max_value)+1\n",
    "\n",
    "\n",
    "gcdf = pd.read_csv(\"lda/lda_prob_6.csv\")\n",
    "\n",
    "gcdf[\"CLUSTER\"] = gcdf.apply(cluster_map, axis=1)\n",
    "\n",
    "gcdf.sort_values(by=\"CLUSTER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=reviews, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Topic Distance Visualization \n",
    "pyLDAvis.enable_notebook()\n",
    "prepare_data = gensimvis.prepare(lda_model, corpus, id2word, mds='mmds') #R=60\n",
    "# html = pyLDAvis.prepared_data_to_html(prepare_data)\n",
    "pyLDAvis.display(prepare_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write string to file\n",
    "text_file = open(f\"lda_{str(CLUSTERS)}.html\", \"w\")\n",
    "text_file.write(html)\n",
    "text_file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df = pd.read_csv(\"../data/review_summarizer/summarized_reviews_by_year_and_hotel-small.csv\");\n",
    "in_df = pd.read_csv(\"../data/exploratory_analysis/tripadvisor_hotels_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REVIEW_CONCATCHAR1 = \"\\n\"\n",
    "\n",
    "def fromDateToYear(value): #Clean CSV (yyyy-mm-dd)\n",
    "    return value.split(\"-\")[0]\n",
    "\n",
    "def concatReviewsByYearAndHotel(df):\n",
    "    df = df.copy()\n",
    "    df[\"REVIEW_DATE\"] = df[\"REVIEW_DATE\"].map(fromDateToYear).astype(int)\n",
    "    df['REVIEW_TEXT'] = df[['HOTEL_NAME','REVIEW_TEXT','REVIEW_DATE']].groupby([\"HOTEL_NAME\",\"REVIEW_DATE\"])[\"REVIEW_TEXT\"].transform(lambda x: REVIEW_CONCATCHAR1.join(x))\n",
    "    return df[['HOTEL_NAME','REVIEW_DATE','REVIEW_TEXT']].drop_duplicates()\n",
    "\n",
    "# Group by NAME and YEAR\n",
    "iny_df = concatReviewsByYearAndHotel(in_df.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_sample = sum_df.sample(1).iloc[0]\n",
    "\n",
    "sum_in_sample = iny_df[(iny_df[\"REVIEW_DATE\"]==sum_sample[\"REVIEW_DATE\"]) & (iny_df[\"HOTEL_NAME\"]==sum_sample[\"HOTEL_NAME\"])].iloc[0]\n",
    "\n",
    "print(\"IN:\")\n",
    "print(sum_in_sample[\"REVIEW_TEXT\"])\n",
    "print(\"OUT:\")\n",
    "print(sum_sample[\"REVIEW_SUMMARY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import datasets [Disclaimer: Get the path to the actual file]\n",
    "df_3s = pd.read_csv(\"../data/Iter2Lda/tripadvisor_hotels_3_clean.csv\") # 3 Stars Hotels\n",
    "df_5sy = pd.read_csv(\"../data/Iter2Lda/tripadvisor_hotels_sustainable_clean_5stars.csv\") # 5 Stars Sustainable Hotels\n",
    "df_5sn = pd.read_csv(\"../data/Iter2Lda/tripadvisor_hotels_nonsustainable_clean_5stars.csv\") # 5 Stars Non-Sustainable Hotels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaned_reviews(df):\n",
    "    # Convert reviews to list\n",
    "    reviews = df[\"REVIEW_TEXT\"].values.tolist()\n",
    "\n",
    "    #Eliminate puntiation marks\n",
    "    reviews = [r.translate(str.maketrans('','',string.punctuation)) for r in reviews]\n",
    "\n",
    "    # Remove numbers\n",
    "    reviews = [''.join([i for i in r if not i.isdigit()]) for r in reviews]\n",
    "\n",
    "    #Lower case\n",
    "    reviews = [r.lower() for r in reviews]\n",
    "\n",
    "    #Split words\n",
    "    reviews = [r.split(' ') for r in reviews]\n",
    "\n",
    "    #Blank spaces\n",
    "    reviews = [list(filter(lambda r: not (not r), review)) for review in reviews]\n",
    "\n",
    "    # Eliminate common words (English stop words)\n",
    "    sw = list(set(stopwords.words('english'))) # English Stop Words \n",
    "    hw = [\"hotel\", \"hotels\", \"here\", \"there\", \"also\", \"big\", \"close\", \n",
    "        \"far\", \"small\", \"well\", \"good\", \"never\", \"ever\", \"bit\", \"next\", \n",
    "        \"little\", \"many\", \"much\", \"minute\", \"minutes\", \"hours\", \"right\", \n",
    "        \"with\", \"within\", \"lot\", \"lots\", \"around\", \"me\", \"us\", \"we\", \n",
    "        \"front\", \"back\", \"stay\", \"went\", \"go\", \"got\", \"would\", \"should\", \n",
    "        \"could\", \"follow\", \"arrive\", \"see\", \"check\",\"one\",\"two\",\"three\",\n",
    "        \"four\",\"five\",\"six\",\"seven\"] # Hotel words\n",
    "    cw = sw + hw\n",
    "    reviews = [list(filter(lambda r: r not in cw, review)) for review in reviews]\n",
    "\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTERS = [3,4,6,8]\n",
    "def create_lda_models(reviews):\n",
    "    id2word = Dictionary(reviews)\n",
    "\n",
    "    # Term Document Frequency\n",
    "    corpus = [id2word.doc2bow(text) for text in reviews]\n",
    "\n",
    "    # Build LDA models (~3m 30s)\n",
    "    lda_models = [LdaModel(corpus=corpus,\n",
    "                    id2word=id2word,\n",
    "                    num_topics=c,\n",
    "                    random_state=0,\n",
    "                    chunksize=100,\n",
    "                    alpha='auto',\n",
    "                    per_word_topics=True) for c in CLUSTERS]\n",
    "    \n",
    "    return lda_models, corpus, id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "def save_lda_visualization(lda_models, corpus, id2word, prefix:str = ''):\n",
    "    prepare_data = [gensimvis.prepare(m, corpus, id2word, mds='mmds') for m in lda_models] #R=60\n",
    "\n",
    "    # Topic distance visualization to html\n",
    "    models_htmls = [pyLDAvis.prepared_data_to_html(d) for d in prepare_data]\n",
    "\n",
    "    # Save htmls\n",
    "    for i, html in enumerate(models_htmls):\n",
    "        text_file = open(f\"../data/lda/lda_{prefix}_{str(CLUSTERS[i])}.html\", \"w\")\n",
    "        text_file.write(html)\n",
    "        text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is taking 10m each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1 (5 Stars Sustainable Hotels + 3 Stars Hotels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat dfs\n",
    "df_d1 = pd.concat([df_3s, df_5sy])\n",
    "\n",
    "# Clean reviews\n",
    "reviews =  cleaned_reviews(df_d1)\n",
    "\n",
    "# Create lda models\n",
    "lda_models, corpus, id2word = create_lda_models(reviews)\n",
    "\n",
    "# Save lda models as htmls\n",
    "save_lda_visualization(lda_models, corpus, id2word, 'd1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2 (5 Stars Non Sustainable Hotels + 3 Stars Hotels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat dfs\n",
    "df_d2 = pd.concat([df_3s, df_5sn])\n",
    "\n",
    "# Clean reviews\n",
    "reviews =  cleaned_reviews(df_d2)\n",
    "\n",
    "# Create lda models\n",
    "lda_models, corpus, id2word = create_lda_models(reviews)\n",
    "\n",
    "# Save lda models as htmls\n",
    "save_lda_visualization(lda_models, corpus, id2word, 'd2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 3 (3 Stars Hotels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean reviews\n",
    "reviews =  cleaned_reviews(df_3s)\n",
    "\n",
    "# Create lda models\n",
    "lda_models, corpus, id2word = create_lda_models(reviews)\n",
    "\n",
    "# Save lda models as htmls\n",
    "save_lda_visualization(lda_models, corpus, id2word, 'd3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32fe028544ad451da7fd425bd970f9d43d891a9dcc481ea9112199e2f0c30cfa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
